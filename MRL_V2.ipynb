{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CL1j2xgFSvip"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTS"
      ],
      "metadata": {
        "id": "H9-Dm2jEP4lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "# !pip install tqdm\n",
        "# !pip install terminaltables\n",
        "# !pip install autocast\n",
        "# # !pip install ch\n",
        "# !pip install pytorch-lightning\n",
        "# !pip install hydra-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgvkRJ8sUftf",
        "outputId": "941d21ac-b2b6-4695-e0bd-404ab442b373"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Collecting pretty-errors==1.2.25 (from torchmetrics)\n",
            "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
            "Collecting colorama (from pretty-errors==1.2.25->torchmetrics)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 torchmetrics-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "import sys\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.cuda.amp import autocast\n",
        "import torch.nn.functional as F\n",
        "import torch.distributed as dist\n",
        "from torchvision import models\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from uuid import uuid4\n",
        "from typing import List\n",
        "from pathlib import Path\n",
        "# from fastargs import get_current_config\n",
        "# from fastargs.decorators import param\n",
        "# from fastargs import Param, Section\n",
        "# from fastargs.validation import And, OneOf\n",
        "\n",
        "# from ffcv.pipeline.operation import Operation\n",
        "# from ffcv.loader import Loader, OrderOption\n",
        "# from ffcv.transforms import ToTensor, ToDevice, Squeeze, NormalizeImage, \\\n",
        "#     RandomHorizontalFlip, ToTorchImage\n",
        "# from ffcv.fields.rgb_image import CenterCropRGBImageDecoder, \\\n",
        "#     RandomResizedCropRGBImageDecoder\n",
        "# from ffcv.fields.basics import IntDecoder"
      ],
      "metadata": {
        "id": "Ql9qDWPkSbnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MATRYOKSHA FUNCTIONS"
      ],
      "metadata": {
        "id": "d83A8zkh8ZuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "Loss function for Matryoshka Representation Learning\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Matryoshka_CE_Loss(nn.Module):\n",
        "    def __init__(self, relative_importance=None, **kwargs):\n",
        "        super(Matryoshka_CE_Loss, self).__init__()\n",
        "        self.criterion = nn.CrossEntropyLoss(**kwargs)\n",
        "        self.relative_importance = relative_importance\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        losses = torch.stack([self.criterion(output_i, target) for output_i in output])\n",
        "        rel_importance = torch.ones_like(losses) if self.relative_importance is None else torch.tensor(self.relative_importance)\n",
        "        weighted_losses = rel_importance * losses\n",
        "        return weighted_losses.sum()\n",
        "\n",
        "class MRL_Linear_Layer(nn.Module):\n",
        "    def __init__(self, nesting_list, num_classes=1000, efficient=False, **kwargs):\n",
        "        super(MRL_Linear_Layer, self).__init__()\n",
        "        self.nesting_list = nesting_list\n",
        "        self.num_classes = num_classes\n",
        "        self.efficient = efficient\n",
        "        if self.efficient:\n",
        "            setattr(self, f'nesting_classifier_{0}', nn.Linear(nesting_list[-1], self.num_classes, **kwargs))\n",
        "        else:\n",
        "            for i, num_feat in enumerate(self.nesting_list):\n",
        "                setattr(self, f'nesting_classifier_{i}', nn.Linear(num_feat, self.num_classes, **kwargs))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.efficient:\n",
        "            self.nesting_classifier_0.reset_parameters()\n",
        "        else:\n",
        "            for i in range(len(self.nesting_list)):\n",
        "                getattr(self, f'nesting_classifier_{i}').reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        nesting_logits = ()\n",
        "        for i, num_feat in enumerate(self.nesting_list):\n",
        "            if self.efficient:\n",
        "                nesting_logits += (getattr(self, f'nesting_classifier_{0}')(x[:, :num_feat]),)\n",
        "            else:\n",
        "                nesting_logits += (getattr(self, f'nesting_classifier_{i}')(x[:, :num_feat]),)\n",
        "        return nesting_logits\n",
        "\n",
        "class FixedFeatureLayer(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, **kwargs):\n",
        "        super(FixedFeatureLayer, self).__init__(in_features, out_features, **kwargs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not (self.bias is None):\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t()) + self.bias\n",
        "        else:\n",
        "            out = torch.matmul(x[:, :self.in_features], self.weight.t())\n",
        "        return out\n",
        "\n",
        "nesting_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2048]\n",
        "fc_layer = MRL_Linear_Layer(nesting_list, num_classes=1000, efficient=True)"
      ],
      "metadata": {
        "id": "-YcITzBXSkCT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INPUTS\n"
      ],
      "metadata": {
        "id": "O22atDzr53jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code is directly taken from FFCV-Imagenet https://github.com/libffcv/ffcv-imagenet\n",
        "and modified for MRL purpose.\n",
        "'''\n",
        "sys.path.append(\"../\") # adding root folder to the path\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "\n",
        "config_file = 'rn50_configs/rn50_40_epochs.yaml'\n",
        "model_fixed_feature = 2048\n",
        "# train_dataset = os.environ['WRITE_DIR'] + '/train_500_0.50_90.ffcv'\n",
        "# val_dataset = os.environ['WRITE_DIR'] + '/val_500_uncompressed.ffcv'\n",
        "num_workers = 12\n",
        "in_memory = True\n",
        "logging_folder = 'trainlogs'\n",
        "log_level = 0\n",
        "world_size = 2\n",
        "distributed = False\n",
        "learning_rate = 0.425\n",
        "\n",
        "arch='resnet18'\n",
        "pretrained=0\n",
        "efficient=0\n",
        "mrl=0\n",
        "nesting_start=3\n",
        "fixed_feature=2048\n",
        "\n",
        "\n",
        "min_res=160\n",
        "max_res=160\n",
        "end_ramp=0\n",
        "start_ramp=0\n",
        "\n",
        "\n",
        "step_ratio=0.1\n",
        "step_length=30\n",
        "lr_schedule_type='cyclic'\n",
        "lr=0.5\n",
        "lr_peak_epoch=2\n",
        "\n",
        "\n",
        "\n",
        "folder=logging_folder\n",
        "\n",
        "\n",
        "batch_size=512\n",
        "resolution=224\n",
        "lr_tta=1\n",
        "\n",
        "\n",
        "eval_only=0\n",
        "path=None\n",
        "batch_size=512\n",
        "optimizer='sgd'\n",
        "momentum=0.9\n",
        "weight_decay=4e-5\n",
        "epochs=15\n",
        "label_smoothing=0.1\n",
        "distributed=0\n",
        "use_blurpool=0\n",
        "\n",
        "\n",
        "\n",
        "address='localhost'\n",
        "port=12355\n",
        "\n"
      ],
      "metadata": {
        "id": "Qet1axJU54jV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASET LOADING"
      ],
      "metadata": {
        "id": "nIKTNuKpSgQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None, label_transform=None):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.label_transform = label_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx].transpose((1, 2, 0))  # Transpose to (32, 32, 3)\n",
        "        label = self.labels[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))  # Convert to PIL Image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.label_transform:\n",
        "            label = self.label_transform(label)\n",
        "        return image, label\n",
        "\n",
        "def load_cifar10_batch(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        batch = pickle.load(fo, encoding='latin1')\n",
        "    data = batch['data']\n",
        "    labels = batch['labels']\n",
        "    data = data.reshape(-1, 3, 32, 32)  # Reshape data\n",
        "    return data, labels\n",
        "\n",
        "def load_cifar10_data(data_dir):\n",
        "    train_data = []\n",
        "    train_labels = []\n",
        "    for i in range(1, 6):\n",
        "        batch_data, batch_labels = load_cifar10_batch(os.path.join(data_dir, f'data_batch_{i}'))\n",
        "        train_data.append(batch_data)\n",
        "        train_labels.extend(batch_labels)\n",
        "    train_data = np.vstack(train_data)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_data, test_labels = load_cifar10_batch(os.path.join(data_dir, 'test_batch'))\n",
        "    test_data = test_data.reshape(-1, 3, 32, 32)\n",
        "    test_labels = np.array(test_labels)\n",
        "    return train_data, train_labels, test_data, test_labels\n",
        "\n",
        "data_dir = 'cifar/'  # Modify with actual path\n",
        "train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)\n",
        "\n",
        "this_device = f'cuda:{0}'\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10), #newly added\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "def label_transform(label):\n",
        "    # Transform labels to tensor\n",
        "    # return torch.tensor(label, dtype=torch.long).to(this_device, non_blocking=True)\n",
        "    return torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform_train, label_transform=label_transform)\n",
        "test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform_test, label_transform=label_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=12)\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWzk88u9Sfc_",
        "outputId": "c98e5b70-28d3-4731-bb4f-c4ec16cf2a0c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HELPER FNS"
      ],
      "metadata": {
        "id": "Iopy55xoTX6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR_MEAN = np.array([0.485, 0.456, 0.406]) * 255\n",
        "CIFAR_STD = np.array([0.229, 0.224, 0.225]) * 255\n",
        "DEFAULT_CROP_RATIO = 224/256\n",
        "\n",
        "def get_step_lr(epoch, lr=lr, step_ratio=step_ratio, step_length=step_length, epochs=epochs):\n",
        "    if epoch >= epochs:\n",
        "        return 0\n",
        "\n",
        "    num_steps = epoch // step_length\n",
        "    return step_ratio**num_steps * lr\n",
        "\n",
        "def get_constant_lr(epoch, lr=lr):\n",
        "    return lr\n",
        "\n",
        "def get_cyclic_lr(epoch, lr=lr, epochs=epochs, lr_peak_epoch=lr_peak_epoch):\n",
        "    xs = [0, lr_peak_epoch, epochs]\n",
        "    ys = [1e-4 * lr, lr, 0]\n",
        "    return np.interp([epoch], xs, ys)[0]\n",
        "\n",
        "class BlurPoolConv2d(torch.nn.Module):\n",
        "    def __init__(self, conv):\n",
        "        super().__init__()\n",
        "        default_filter = torch.tensor([[[[1, 2, 1], [2, 4, 2], [1, 2, 1]]]]) / 16.0\n",
        "        filt = default_filter.repeat(conv.in_channels, 1, 1, 1)\n",
        "        self.conv = conv\n",
        "        self.register_buffer('blur_filter', filt)\n",
        "\n",
        "    def forward(self, x):\n",
        "        blurred = F.conv2d(x, self.blur_filter, stride=1, padding=(1, 1),\n",
        "                           groups=self.conv.in_channels, bias=None)\n",
        "        return self.conv.forward(blurred)\n"
      ],
      "metadata": {
        "id": "0E8qlNRlTa__"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFARTrainer"
      ],
      "metadata": {
        "id": "1MjO82k2Tlfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CIFARTrainer:\n",
        "    def __init__(self, gpu, train_loader = train_loader, val_loader=val_loader,distributed=distributed, efficient=efficient, mrl=mrl, nesting_start=nesting_start, fixed_feature=fixed_feature,\n",
        "                 this_device=  this_device):\n",
        "        # self.all_params = get_current_config();\n",
        "        self.gpu = gpu\n",
        "        self.efficient = efficient\n",
        "        self.nesting = (self.efficient or mrl)\n",
        "        self.nesting_start = nesting_start\n",
        "        self.nesting_list = [2**i for i in range(self.nesting_start, 12)] if self.nesting else None\n",
        "        self.fixed_feature=fixed_feature\n",
        "        self.uid = str(uuid4())\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        self.this_device = this_device\n",
        "\n",
        "\n",
        "        if distributed:\n",
        "            self.setup_distributed()\n",
        "\n",
        "        self.model, self.scaler = self.create_model_and_scaler()\n",
        "        # self.model.cuda().half()\n",
        "        self.create_optimizer()\n",
        "        self.initialize_logger()\n",
        "\n",
        "\n",
        "    def setup_distributed(self, address=address, port=port, world_size=world_size):\n",
        "        os.environ['MASTER_ADDR'] = address\n",
        "        os.environ['MASTER_PORT'] = port\n",
        "\n",
        "        dist.init_process_group(\"nccl\", rank=self.gpu, world_size=world_size)\n",
        "        torch.cuda.set_device(self.gpu)\n",
        "\n",
        "    def cleanup_distributed(self):\n",
        "        dist.destroy_process_group()\n",
        "\n",
        "    def get_lr(self, epoch, lr_schedule_type=lr_schedule_type):\n",
        "        lr_schedules = {\n",
        "            'cyclic': get_cyclic_lr,\n",
        "            'step': get_step_lr,\n",
        "            'constant': get_constant_lr\n",
        "        }\n",
        "\n",
        "        return lr_schedules[lr_schedule_type](epoch)\n",
        "\n",
        "    # resolution tools\n",
        "    def get_resolution(self, epoch, min_res=min_res, max_res=max_res, end_ramp=end_ramp, start_ramp=start_ramp):\n",
        "        assert min_res <= max_res\n",
        "\n",
        "        if epoch <= start_ramp:\n",
        "            return min_res\n",
        "\n",
        "        if epoch >= end_ramp:\n",
        "            return max_res\n",
        "\n",
        "        # otherwise, linearly interpolate to the nearest multiple of 32\n",
        "        interp = np.interp([epoch], [start_ramp, end_ramp], [min_res, max_res])\n",
        "        final_res = int(np.round(interp[0] / 32)) * 32\n",
        "        return final_res\n",
        "\n",
        "    def create_optimizer(self, momentum=momentum, optimizer=optimizer, weight_decay=weight_decay,\n",
        "                         label_smoothing=label_smoothing):\n",
        "        assert optimizer == 'sgd'\n",
        "\n",
        "        # Only do weight decay on non-batchnorm parameters\n",
        "        all_params = list(self.model.named_parameters())\n",
        "        bn_params = [v for k, v in all_params if ('bn' in k)]\n",
        "        other_params = [v for k, v in all_params if not ('bn' in k)]\n",
        "        param_groups = [{\n",
        "            'params': bn_params,\n",
        "            'weight_decay': 0.\n",
        "        }, {\n",
        "            'params': other_params,\n",
        "            'weight_decay': weight_decay\n",
        "        }]\n",
        "\n",
        "        self.optimizer = torch.optim.SGD(param_groups, lr=1, momentum=momentum)\n",
        "        # Adding Nesting Case....\n",
        "        if self.nesting:\n",
        "            self.loss = Matryoshka_CE_Loss(label_smoothing=label_smoothing)\n",
        "        else:\n",
        "            self.loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "    def train(self, epochs=epochs, log_level=log_level):\n",
        "        for epoch in range(epochs):\n",
        "            print(\"epoch no. \", epoch)\n",
        "            # res = self.get_resolution(epoch)\n",
        "            # self.decoder.output_size = (res, res)\n",
        "            train_loss = self.train_loop(epoch)\n",
        "\n",
        "            if log_level > 0:\n",
        "                extra_dict = {\n",
        "                    'train_loss': train_loss,\n",
        "                    'epoch': epoch\n",
        "                }\n",
        "\n",
        "                self.eval_and_log(extra_dict)\n",
        "\n",
        "        # self.eval_and_log({'epoch':epoch})\n",
        "        if self.gpu == 0:\n",
        "            torch.save(self.model.state_dict(), self.log_folder / 'final_weights.pt')\n",
        "\n",
        "    def eval_and_log(self, extra_dict={}):\n",
        "        start_val = time.time()\n",
        "        if self.nesting:\n",
        "            stats = self.val_loop_nesting()\n",
        "        else:\n",
        "            stats = self.val_loop()\n",
        "        val_time = time.time() - start_val\n",
        "\n",
        "        if self.gpu == 0:\n",
        "            d = {\n",
        "                'current_lr': self.optimizer.param_groups[0]['lr'], 'val_time': val_time\n",
        "            }\n",
        "            for k in stats.keys():\n",
        "                if k=='loss':\n",
        "                    continue\n",
        "                else:\n",
        "                    d[k]=stats[k]\n",
        "\n",
        "            self.log(dict(d, **extra_dict))\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def create_model_and_scaler(self, arch=arch, pretrained=pretrained, distributed=distributed, use_blurpool=use_blurpool):\n",
        "        '''\n",
        "        Nesting Start is just the log_2 {smallest dim} unit. In our work we used powers of two, however this part can be changed easily.\n",
        "        If we do not want to use MRL, we just keep both the efficient and mrl flags to 0\n",
        "        If we want a fixed feature baseline, then we just change fixed_feature={Rep. Size of your choice}\n",
        "\n",
        "        NOTE: FFCV Uses Blurpool.\n",
        "        '''\n",
        "\n",
        "        scaler = GradScaler()\n",
        "        model = getattr(models, arch)(pretrained=pretrained)\n",
        "\n",
        "        if self.nesting:\n",
        "            ff= \"MRL-E\" if self.efficient else \"MRL\"\n",
        "            print(f\"Creating classification layer of type :\\t {ff}\")\n",
        "            model.fc = MRL_Linear_Layer(self.nesting_list, num_classes=1000, efficient=self.efficient)\n",
        "        elif self.fixed_feature != 2048:\n",
        "            print(\"Using Fixed Features.... \")\n",
        "            model.fc =  FixedFeatureLayer(self.fixed_feature, 1000)\n",
        "\n",
        "        def apply_blurpool(mod: torch.nn.Module):\n",
        "            for (name, child) in mod.named_children():\n",
        "                if isinstance(child, torch.nn.Conv2d) and (np.max(child.stride) > 1 and child.in_channels >= 16):\n",
        "                    setattr(mod, name, BlurPoolConv2d(child))\n",
        "                else: apply_blurpool(child)\n",
        "        if use_blurpool: apply_blurpool(model)\n",
        "\n",
        "        model = model.to(memory_format=torch.channels_last)\n",
        "        model = model.to(self.gpu)\n",
        "\n",
        "        if distributed:\n",
        "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[self.gpu])\n",
        "\n",
        "        return model, scaler\n",
        "\n",
        "    def train_loop(self, epoch, log_level=log_level):\n",
        "        model = self.model\n",
        "        model.train()\n",
        "        losses = []\n",
        "\n",
        "        lr_start, lr_end = self.get_lr(epoch), self.get_lr(epoch + 1)\n",
        "        iters = len(self.train_loader)\n",
        "        lrs = np.interp(np.arange(iters), [0, iters], [lr_start, lr_end])\n",
        "\n",
        "        iterator = tqdm(self.train_loader)\n",
        "        for ix, (images, target) in enumerate(iterator):\n",
        "            images = images.to(self.this_device, non_blocking=True)\n",
        "            target = target.to(self.this_device, non_blocking=True)\n",
        "            ### Training start\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = lrs[ix]\n",
        "\n",
        "            self.optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast():\n",
        "                # images = images.cuda().half()\n",
        "\n",
        "                output = self.model(images)\n",
        "                loss_train = self.loss(output, target)\n",
        "\n",
        "            self.scaler.scale(loss_train).backward()\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "            ### Training end\n",
        "\n",
        "            ### Logging start\n",
        "            if log_level > 0:\n",
        "                losses.append(loss_train.detach())\n",
        "\n",
        "                group_lrs = []\n",
        "                for _, group in enumerate(self.optimizer.param_groups):\n",
        "                    group_lrs.append(f'{group[\"lr\"]:.3f}')\n",
        "\n",
        "                names = ['ep', 'iter', 'shape', 'lrs']\n",
        "                values = [epoch, ix, tuple(images.shape), group_lrs]\n",
        "                if log_level > 1:\n",
        "                    names += ['loss']\n",
        "                    values += [f'{loss_train.item():.3f}']\n",
        "\n",
        "                msg = ', '.join(f'{n}={v}' for n, v in zip(names, values))\n",
        "                iterator.set_description(msg)\n",
        "            ### Logging end\n",
        "\n",
        "        if log_level > 0:\n",
        "            loss = torch.stack(losses).mean().cpu()\n",
        "            assert not torch.isnan(loss), 'Loss is NaN!'\n",
        "            return loss.item()\n",
        "\n",
        "    def val_loop(self, lr_tta=lr_tta):\n",
        "        model = self.model\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                for images, target in tqdm(self.val_loader):\n",
        "                    images = images.to(self.this_device, non_blocking=True)\n",
        "                    target = target.to(self.this_device, non_blocking=True)\n",
        "                    images = images.cuda().half()\n",
        "                    output = self.model(images)\n",
        "                    if lr_tta:\n",
        "                        output += self.model(torch.flip(images, dims=[3]))\n",
        "\n",
        "                    for k in ['top_1', 'top_5']:\n",
        "                        self.val_meters[k](output, target)\n",
        "\n",
        "                    loss_val = self.loss(output, target)\n",
        "                    self.val_meters['loss'](loss_val)\n",
        "\n",
        "        stats = {k: m.compute().item() for k, m in self.val_meters.items()}\n",
        "        [meter.reset() for meter in self.val_meters.values()]\n",
        "        return stats\n",
        "\n",
        "\n",
        "    def val_loop_nesting(self, lr_tta=lr_tta):\n",
        "        '''\n",
        "        Since Nested Layers will give a tuple of logits, we have a different subroutine for validation.\n",
        "        '''\n",
        "\n",
        "        model = self.model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                for images, target in tqdm(self.val_loader):\n",
        "                    images = images.to(self.this_device, non_blocking=True)\n",
        "                    target = target.to(self.this_device, non_blocking=True)\n",
        "                    output = self.model(images); output=torch.stack(output, dim=0)\n",
        "\n",
        "                    if lr_tta:\n",
        "                        output +=torch.stack(self.model(torch.flip(images, dims=[3])), dim=0) # Just one augmentation.\n",
        "\n",
        "                    # Logging the accuracies top1/5 for each of nesting...\n",
        "                    for i in range(len(self.nesting_list)):\n",
        "                        s = \"top_1_{}\".format(self.nesting_list[i])\n",
        "                        self.val_meters[s](output[i], target)\n",
        "                        s = \"top_5_{}\".format(self.nesting_list[i])\n",
        "                        self.val_meters[s](output[i], target)\n",
        "\n",
        "                    loss_val = self.loss(output, target)\n",
        "                    self.val_meters['loss'](loss_val)\n",
        "\n",
        "        stats = {k: m.compute().item() for k, m in self.val_meters.items()}\n",
        "        [meter.reset() for meter in self.val_meters.values()]\n",
        "        return stats\n",
        "\n",
        "\n",
        "    def initialize_logger(self, folder=folder):\n",
        "        if self.nesting:\n",
        "            self.val_meters={}\n",
        "            for i in self.nesting_list:\n",
        "                self.val_meters['top_1_{}'.format(i)] = torchmetrics.Accuracy(compute_on_step=False).to(self.gpu)\n",
        "\n",
        "            for i in self.nesting_list:\n",
        "                self.val_meters['top_5_{}'.format(i)] = torchmetrics.Accuracy(compute_on_step=False, top_k=5).to(self.gpu)\n",
        "\n",
        "            self.val_meters['loss'] = MeanScalarMetric(compute_on_step=False).to(self.gpu)\n",
        "\n",
        "        else:\n",
        "            self.val_meters = {\n",
        "                'top_1': torchmetrics.Accuracy(task='multiclass', num_classes=10).to(self.gpu),\n",
        "                'top_5': torchmetrics.Accuracy(task='multiclass', top_k=5, num_classes=10).to(self.gpu),\n",
        "                'loss': MeanScalarMetric().to(self.gpu)\n",
        "            }\n",
        "\n",
        "        if self.gpu == 0:\n",
        "            folder = (Path(folder) / str(self.uid)).absolute()\n",
        "            folder.mkdir(parents=True)\n",
        "\n",
        "            self.log_folder = folder\n",
        "            self.start_time = time.time()\n",
        "\n",
        "            print(f'=> Logging in {self.log_folder}')\n",
        "            # params = {\n",
        "            #     '.'.join(k): self.all_params[k] for k in self.all_params.entries.keys()\n",
        "            # }\n",
        "\n",
        "            # with open(folder / 'params.json', 'w+') as handle:\n",
        "            #     json.dump(params, handle)\n",
        "\n",
        "    def log(self, content):\n",
        "        print(f'=> Log: {content}')\n",
        "        if self.gpu != 0: return\n",
        "        cur_time = time.time()\n",
        "        with open(self.log_folder / 'log', 'a+') as fd:\n",
        "            fd.write(json.dumps({\n",
        "                'timestamp': cur_time,\n",
        "                'relative_time': cur_time - self.start_time,\n",
        "                **content\n",
        "            }) + '\\n')\n",
        "            fd.flush()\n",
        "\n",
        "    @classmethod\n",
        "    def launch_from_args(cls, distributed=False, world_size=2, eval_only=0):\n",
        "        if distributed:\n",
        "            torch.multiprocessing.spawn(cls._exec_wrapper, nprocs=world_size, join=True)\n",
        "        else:\n",
        "            cls.exec(0, distributed, eval_only)\n",
        "\n",
        "    @classmethod\n",
        "    def _exec_wrapper(cls, *args, **kwargs):\n",
        "        make_config(quiet=True)\n",
        "        cls.exec(*args, **kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def exec(cls, gpu, distributed=distributed, eval_only=eval_only, path=None):\n",
        "        trainer = cls(gpu=gpu)\n",
        "        if eval_only:\n",
        "            print(\"Loading Model.....\"); ckpt = torch.load(path, map_location=\"cuda:{}\".format(gpu))\n",
        "            trainer.model.load_state_dict(ckpt); print(\"Loading Complete!\")\n",
        "            trainer.eval_and_log()\n",
        "        else:\n",
        "            trainer.train()\n",
        "\n",
        "        if distributed:\n",
        "            trainer.cleanup_distributed()\n",
        "\n",
        "# Utils\n",
        "class MeanScalarMetric(torchmetrics.Metric):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.add_state('sum', default=torch.tensor(0.), dist_reduce_fx='sum')\n",
        "        self.add_state('count', default=torch.tensor(0), dist_reduce_fx='sum')\n",
        "\n",
        "    def update(self, sample: torch.Tensor):\n",
        "        self.sum += sample.sum()\n",
        "        self.count += sample.numel()\n",
        "\n",
        "    def compute(self):\n",
        "        return self.sum.float() / self.count\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dtvWwTZrSZbZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running\n",
        "# def make_config(quiet=False):\n",
        "#     config = get_current_config()\n",
        "#     parser = ArgumentParser(description='Fast CIFAR training')\n",
        "#     config.validate(mode='stderr')\n",
        "#     if not quiet:\n",
        "#         config.summary()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # make_config()\n",
        "    CIFARTrainer.launch_from_args(distributed, world_size, eval_only)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uo6HjBlsT9KA",
        "outputId": "b6047cc2-5a24-458f-81e3-b9a559b2038c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Logging in /content/trainlogs/a3d1ec18-cb77-4d9c-89d1-c258b621acd4\n",
            "epoch no.  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|██████████| 391/391 [00:32<00:00, 11.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:36<00:00, 10.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:36<00:00, 10.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:36<00:00, 10.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:33<00:00, 11.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00,  9.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:35<00:00, 11.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:36<00:00, 10.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:34<00:00, 11.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:35<00:00, 11.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:35<00:00, 11.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch no.  29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.35it/s]\n",
            "  0%|          | 0/79 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b4fa3080d684>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# make_config()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mCIFARTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_from_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-0e0fd189769d>\u001b[0m in \u001b[0;36mlaunch_from_args\u001b[0;34m(cls, distributed, world_size, eval_only)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-0e0fd189769d>\u001b[0m in \u001b[0;36mexec\u001b[0;34m(cls, gpu, distributed, eval_only, path)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-0e0fd189769d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, log_level)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_and_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_folder\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'final_weights.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-0e0fd189769d>\u001b[0m in \u001b[0;36meval_and_log\u001b[0;34m(self, extra_dict)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop_nesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mval_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-0e0fd189769d>\u001b[0m in \u001b[0;36mval_loop\u001b[0;34m(self, lr_tta)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'top_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'top_5'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_meters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_full_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_reduce_state_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# calculate batch state and compute batch value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mbatch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/classification/stat_scores.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;34m\"\"\"Update state with predictions and targets.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             _multiclass_stat_scores_tensor_validation(\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultidim_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/classification/stat_scores.py\u001b[0m in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If `preds` have one dimension more than `target`, `preds` should be a float tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    284\u001b[0m                 \u001b[0;34m\"If `preds` have one dimension more than `target`, `preds.shape[1]` should be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;34m\" equal to number of classes.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes."
          ]
        }
      ]
    }
  ]
}